{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## TSMixer: An All-MLP Architecture for Time Series Forecasting\n\n##### Documentation:\nhttps://unit8co.github.io/darts/generated_api/darts.models.forecasting.tsmixer_model.html\n\n##### Paper:\nhttps://arxiv.org/abs/2303.06053\n\n### Important Terms\n<b>Past covariates:</b> Time series whose past values are known at prediction time. Those series often contain values that have to be observed to be known.\n\n<b>Future covariates:</b> Time series whose future values are already known at prediction time for the span of the forecast horizon. These can for instance represent known future holidays, or weather forecasts.\n\n<b>Static covariates:</b> Constant over time (e.g., district name).\n\n### Used Methods\n\nCells with bold fonts indicate the decided methods for the last submission.\n\n| Segmentation  | Models             | Time       | Aggregation | Training              |\n|---------------|--------------------|------------|-------------|-----------------------|\n| <b>City</b>   | <b>TSMixerModel</b>| 1h         | <b>Mean</b> | <b>Train all once</b> |\n| District      | TideModel          | <b>6h</b>  | <b>Std</b>  | Train per il          |\n| TS Clustering | RNN (LSTM and GRU) | <b>8h</b>  | Min         | Train per ilce        |\n| PCA           | DLinearModel       | <b>12h</b> | Max         |                       |\n|               | NLinearModel       | <b>24h</b> | Skew        |                       |\n|               |                    |            | Kurt        |                       |","metadata":{}},{"cell_type":"code","source":"!pip install -qq darts # See https://unit8co.github.io/darts/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T14:00:59.453621Z","iopub.execute_input":"2024-05-21T14:00:59.454421Z","iopub.status.idle":"2024-05-21T14:01:22.361940Z","shell.execute_reply.started":"2024-05-21T14:00:59.454383Z","shell.execute_reply":"2024-05-21T14:01:22.360644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nfrom tqdm import tqdm\nfrom datetime import date\nfrom itertools import product\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\n\nimport darts\nfrom darts import TimeSeries\nfrom darts.models import TiDEModel, TSMixerModel, RNNModel, NaiveEnsembleModel\nfrom darts.dataprocessing.transformers import Scaler\nfrom darts.utils.missing_values import fill_missing_values\nfrom darts.utils.statistics import plot_acf, plot_pacf, check_seasonality\n\nimport torch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:24.364918Z","iopub.execute_input":"2024-05-21T14:01:24.365347Z","iopub.status.idle":"2024-05-21T14:01:40.010302Z","shell.execute_reply.started":"2024-05-21T14:01:24.365311Z","shell.execute_reply":"2024-05-21T14:01:40.009122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregation rules\nweather_schema = {\n    \"t_2m:C\": [\"mean\", \"std\"],\n    \"effective_cloud_cover:p\": [\"mean\", \"std\"],\n    \"global_rad:W\": [\"mean\", \"std\"],\n    \"relative_humidity_2m:p\": [\"mean\", \"std\"],\n    \"wind_dir_10m:d\": [\"mean\", \"std\"],\n    \"wind_speed_10m:ms\": [\"mean\", \"std\"],\n    \"prob_precip_1h:p\": [\"mean\", \"std\"],\n    \"t_apparent:C\": [\"mean\", \"std\"],\n}\n\n# Encoder for future covariates\nencoders = {\n    'cyclic': {'future': ['dayofyear']},\n    'datetime_attribute': {'future': ['dayofweek']},\n    'position': {'past': ['relative'], 'future': ['relative']},\n    'transformer': Scaler(StandardScaler()),\n}\n\n# Directory path\nroot = Path(\"/kaggle/input/gdz-elektrik-datathon-2024\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.012625Z","iopub.execute_input":"2024-05-21T14:01:40.013444Z","iopub.status.idle":"2024-05-21T14:01:40.021064Z","shell.execute_reply.started":"2024-05-21T14:01:40.013401Z","shell.execute_reply":"2024-05-21T14:01:40.019878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"def get_schema_output(schema:dict) -> list[str]:\n    '''\n    Extract output column names based on aggregation schema\n    \n    Parameters\n    ----------\n    schema: dict\n        A dictionary where keys are column names and values are lists of aggregation functions to apply to each column.\n    \n    Returns\n    -------\n    list:\n        A list of formatted column names based on the applied aggregations.\n    '''\n    col_names = []\n    \n    for col, agg_list in schema.items():\n        col_names.extend([f\"{agg}_{col}\" for agg in agg_list])\n        \n    return col_names","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.022282Z","iopub.execute_input":"2024-05-21T14:01:40.022591Z","iopub.status.idle":"2024-05-21T14:01:40.049825Z","shell.execute_reply.started":"2024-05-21T14:01:40.022566Z","shell.execute_reply":"2024-05-21T14:01:40.048667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def aggregate(schema:dict) -> list[pl.Expr]:\n    '''\n    Generate aggregation expressions for polars\n    \n    Parameters\n    ----------\n    schema: dict\n        A dictionary where keys are column names and values are lists of aggregation functions to apply to each column.\n    \n    Returns\n    -------\n    list:\n        A list of dynamically generated polars expressions.\n    '''\n    expr_list = []\n    \n    for col, agg_list in schema.items():\n        for agg in agg_list:\n            expr = f'[pl.col(\"{col}\").{agg}().alias(\"{agg}_{col}\")]'\n            expr_list = expr_list + eval(expr)\n    \n    return expr_list","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.052376Z","iopub.execute_input":"2024-05-21T14:01:40.052739Z","iopub.status.idle":"2024-05-21T14:01:40.062994Z","shell.execute_reply.started":"2024-05-21T14:01:40.052700Z","shell.execute_reply":"2024-05-21T14:01:40.061651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(train_path:str, test_path:str) -> pl.DataFrame:\n    '''\n    Read and preprocess data\n    \n    Parameters\n    ----------\n    train_path: str\n        Training file path.\n    \n    test_path: str\n        Test file path.\n    \n    Returns\n    -------\n    pl.DataFrame:\n        Concatenated polars dataframe that missing dates filled with 0.\n    '''\n    return (\n        pl.concat([\n            pl.read_csv(\n                train_path, \n                try_parse_dates=True,\n            ),\n            pl.read_csv(\n                test_path, \n                try_parse_dates=True,\n            ).with_columns(\n                pl.lit(0).alias(\"bildirimsiz_sum\"),\n            )\n            .select(\"tarih\", \"ilce\", \"bildirimsiz_sum\", \"bildirimli_sum\"),\n        ], how=\"vertical_relaxed\")\n        .pivot(\n            index=\"tarih\",\n            columns=\"ilce\",\n            values=[\"bildirimsiz_sum\", \"bildirimli_sum\"],\n        )\n        .sort(\"tarih\")\n        .upsample(\"tarih\", every=\"1d\")\n        .fill_null(0)\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.064230Z","iopub.execute_input":"2024-05-21T14:01:40.064588Z","iopub.status.idle":"2024-05-21T14:01:40.079105Z","shell.execute_reply.started":"2024-05-21T14:01:40.064556Z","shell.execute_reply":"2024-05-21T14:01:40.077871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_subm(path:str) -> pd.DataFrame:\n    '''\n    Read submission data\n    \n    Parameters\n    ----------\n    path: str\n        Submission file path.\n    \n    Returns\n    -------\n    pd.DataFrame:\n        Submission table.\n    '''\n    return (\n        pd.read_csv(path)\n        .set_index(\"unique_id\")\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.080423Z","iopub.execute_input":"2024-05-21T14:01:40.080851Z","iopub.status.idle":"2024-05-21T14:01:40.090759Z","shell.execute_reply.started":"2024-05-21T14:01:40.080809Z","shell.execute_reply":"2024-05-21T14:01:40.089699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weather(path:str, schema:dict, every:str=\"24h\", level:str=\"ilce\") -> pl.DataFrame:\n    '''\n    Process weather data\n    \n    Parameters\n    ----------\n    path: str\n        Weather file path.\n    \n    schema: dict\n        A dictionary where keys are column names and values are lists of aggregation functions to apply to each column.\n    \n    every: str\n        Time frequency downsampling rule. It can take values between 1h...24h.\n        \n    level:str:\n        Region level to aggregate. It can take values in [\"il\", \"ilce\"].\n    \n    Returns\n    -------\n    pl.DataFrame:\n        Weather table.\n    '''\n    return (\n        pl.read_csv(path, try_parse_dates=True)\n        .rename({\"name\": \"ilce\"})\n        .with_columns(\n            il = pl.col(\"ilce\").str.split(by=\"-\").list[0],\n        )\n        .sort(\"date\", \"il\", \"ilce\")\n        .group_by_dynamic(\n            \"date\",\n            every=every,\n            group_by=level,\n        )\n        .agg(aggregate(schema))\n        .with_columns(\n            hour = pl.col(\"date\").dt.hour(),\n            date = pl.col(\"date\").dt.date(),\n        )\n        .pivot(\n            index=[\"date\"],\n            columns=[\"hour\", level],\n            values=get_schema_output(schema),\n        )\n        .drop(\"il\", \"ilce\")\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.092075Z","iopub.execute_input":"2024-05-21T14:01:40.092419Z","iopub.status.idle":"2024-05-21T14:01:40.104053Z","shell.execute_reply.started":"2024-05-21T14:01:40.092391Z","shell.execute_reply":"2024-05-21T14:01:40.102609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_eng(df_data:pl.DataFrame, df_weather:pl.DataFrame) -> pd.DataFrame:\n    '''\n    Feature engineering\n    \n    Parameters\n    ----------\n    df_data: pl.DataFrame\n        Training table.\n        \n    df_weather: pl.DataFrame\n        Weather table.\n    \n    Returns\n    -------\n    pd.DataFrame:\n        Final version of training table.\n    '''\n    return (\n        df_data\n        .join(df_weather, how=\"left\", left_on=\"tarih\", right_on=\"date\")\n        .to_pandas()\n        .set_index(\"tarih\")\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.105838Z","iopub.execute_input":"2024-05-21T14:01:40.106283Z","iopub.status.idle":"2024-05-21T14:01:40.121320Z","shell.execute_reply.started":"2024-05-21T14:01:40.106241Z","shell.execute_reply":"2024-05-21T14:01:40.120183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_timeseries(df_data:pd.DataFrame) -> darts.TimeSeries:\n    '''\n    Convert DataFrame to TimeSeries\n    \n    Parameters\n    ----------\n    df_data: pd.DataFrame\n        Training table.\n    \n    Returns\n    -------\n    darts.TimeSeries:\n        A multivariate time series.\n    '''\n    return TimeSeries.from_dataframe(\n        df_data\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.122668Z","iopub.execute_input":"2024-05-21T14:01:40.123335Z","iopub.status.idle":"2024-05-21T14:01:40.132447Z","shell.execute_reply.started":"2024-05-21T14:01:40.123293Z","shell.execute_reply":"2024-05-21T14:01:40.131337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def handle_pred(pred:darts.TimeSeries) -> pd.DataFrame:\n    '''\n    Convert TimeSeries forecasts to submission ready format\n    \n    Parameters\n    ----------\n    pred: darts.TimeSeries\n        Deep learning model forecasts.\n    \n    Returns\n    -------\n    pd.DataFrame:\n        Forecasts in submission ready format.\n    '''\n    pred = pred.pd_dataframe()\n    \n    pred.columns = [col.split(\"_\")[-1] for col in pred.columns]\n    \n    pred = pred.reset_index()\n    pred = pred.melt(id_vars=\"tarih\", value_vars=pred.columns[1:])\n    \n    pred[\"unique_id\"] = pred[\"tarih\"].astype(str) + \"-\" + pred[\"variable\"]\n    \n    pred = pred.drop(columns=[\"tarih\", \"variable\"])\n    pred = pred.set_index(\"unique_id\")\n    pred = pred.rename(columns={\"value\": \"bildirimsiz_sum\"})\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:40.136643Z","iopub.execute_input":"2024-05-21T14:01:40.137332Z","iopub.status.idle":"2024-05-21T14:01:40.146544Z","shell.execute_reply.started":"2024-05-21T14:01:40.137298Z","shell.execute_reply":"2024-05-21T14:01:40.145492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"df_weather = get_weather(\n    path=root / \"weather.csv\", \n    schema=weather_schema, \n    every=\"24h\", \n    level=\"il\",\n)\n\ndf_data = get_data(\n    train_path=root / \"train.csv\", \n    test_path=root / \"test.csv\",\n)\n\ndf_data = feature_eng(\n    df_data=df_data, \n    df_weather=df_weather,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:51.165333Z","iopub.execute_input":"2024-05-21T14:01:51.165749Z","iopub.status.idle":"2024-05-21T14:01:52.170078Z","shell.execute_reply.started":"2024-05-21T14:01:51.165716Z","shell.execute_reply":"2024-05-21T14:01:52.167986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nOutages in district A also affect outages in district B. \nThat's why we estimate all districts at once.\n'''\n\ndf_data.info(verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:52.173083Z","iopub.execute_input":"2024-05-21T14:01:52.173806Z","iopub.status.idle":"2024-05-21T14:01:52.194441Z","shell.execute_reply.started":"2024-05-21T14:01:52.173737Z","shell.execute_reply":"2024-05-21T14:01:52.193650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization - District","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 5))\n\nsegment = 'bildirimsiz_sum_ilce_izmir-aliaga'\n\nseries = to_timeseries(df_data)\nseries = series.slice(pd.Timestamp(\"20231201\"), pd.Timestamp(\"20240201\"))\nseries = series[segment]\nseries.plot()\n\nplt.title(segment)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:52.195818Z","iopub.execute_input":"2024-05-21T14:01:52.196373Z","iopub.status.idle":"2024-05-21T14:01:52.771100Z","shell.execute_reply.started":"2024-05-21T14:01:52.196340Z","shell.execute_reply":"2024-05-21T14:01:52.770007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization - District & Weather Relationship","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 5))\n\nsegment = 'bildirimsiz_sum_ilce_izmir-konak'\n\nseries = to_timeseries(df_data)\nseries = series.slice(pd.Timestamp(\"20231201\"), pd.Timestamp(\"20240201\"))\nseries = series[segment]\nseries.plot()\n\nweather = 'mean_prob_precip_1h:p_{\"hour\",\"il\"}_{0,\"Izmir\"}'\n\nseries = to_timeseries(df_data)\nseries = series.slice(pd.Timestamp(\"20231201\"), pd.Timestamp(\"20240201\"))\nseries = series[weather]\nseries.plot()\n\nplt.title(segment)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:52.773632Z","iopub.execute_input":"2024-05-21T14:01:52.774460Z","iopub.status.idle":"2024-05-21T14:01:53.282248Z","shell.execute_reply.started":"2024-05-21T14:01:52.774419Z","shell.execute_reply":"2024-05-21T14:01:53.281196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization - District & District Relationship","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 5))\n\nsegments = ['bildirimsiz_sum_ilce_izmir-konak','bildirimsiz_sum_ilce_izmir-bornova']\n\nseries = to_timeseries(df_data)\nseries = series.slice(pd.Timestamp(\"20231201\"), pd.Timestamp(\"20240201\"))\nseries = series[segments]\nseries.plot()\n\nplt.title(segments)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:53.283507Z","iopub.execute_input":"2024-05-21T14:01:53.283851Z","iopub.status.idle":"2024-05-21T14:01:53.789450Z","shell.execute_reply.started":"2024-05-21T14:01:53.283819Z","shell.execute_reply":"2024-05-21T14:01:53.788346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time Series Analysis","metadata":{}},{"cell_type":"markdown","source":"### Partial Auto Correlation","metadata":{}},{"cell_type":"code","source":"segment = \"bildirimsiz_sum_ilce_manisa-akhisar\"\n\nseries = to_timeseries(df_data)\nseries = fill_missing_values(series[segment])\nseries = series.drop_after(pd.Timestamp(\"20240201\"))\n\nplot_pacf(series, m=7, alpha=0.05, max_lag=30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:53.791678Z","iopub.execute_input":"2024-05-21T14:01:53.792573Z","iopub.status.idle":"2024-05-21T14:01:54.114937Z","shell.execute_reply.started":"2024-05-21T14:01:53.792532Z","shell.execute_reply":"2024-05-21T14:01:54.113867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check Seasonality","metadata":{}},{"cell_type":"code","source":"segment = \"bildirimsiz_sum_ilce_izmir-konak\"\n\nseries = to_timeseries(df_data)\nseries = fill_missing_values(series[segment])\nseries = series.drop_after(pd.Timestamp(\"20240201\"))\n\nprint(\"Seasonality(7): \", check_seasonality(series, m=7, max_lag=365))\nprint(\"Seasonality(7): \", check_seasonality(series, m=30, max_lag=365))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:54.116595Z","iopub.execute_input":"2024-05-21T14:01:54.116937Z","iopub.status.idle":"2024-05-21T14:01:54.139505Z","shell.execute_reply.started":"2024-05-21T14:01:54.116909Z","shell.execute_reply":"2024-05-21T14:01:54.137976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Step","metadata":{}},{"cell_type":"code","source":"# Convert DataFrame to TimeSeries\nseries = to_timeseries(df_data)\n\n# Fill missing values in the time series\nseries = fill_missing_values(series)\n\n# Extract target columns (columns containing \"bildirimsiz_sum\") and future covariate columns\nis_target = series.columns.str.contains(\"bildirimsiz_sum\")\n\ntarget_cols = list(series.columns[is_target])\nfuture_covariate_cols = list(series.columns[~is_target])\n\n# Extract future covariates from the series\nfuture_covariates = series[future_covariate_cols]\n\n# Split the series into train, validation, and test sets based on time\ntrain_series, test_series = series.split_before(pd.Timestamp(\"20240201\"))\ntrain_series, val_series = train_series.split_before(pd.Timestamp(\"20240104\"))\n\n# Extract target variables from train and validation\ntrain_target = train_series[target_cols]\nval_target = val_series[target_cols]\n\n# Define the TSMixerModel with specific parameters\nmodel = TSMixerModel(\n    input_chunk_length=12,\n    output_chunk_length=4,\n    add_encoders=encoders,\n    num_blocks=4,\n    optimizer_kwargs={\"lr\": 3e-4},\n    loss_fn=torch.nn.L1Loss(),\n    n_epochs=100,\n    batch_size=32,\n    random_state=42,\n    # pl_trainer_kwargs={\"accelerator\": \"gpu\"}, # Uncomment for GPU acceleration\n)\n\n# Fit the model to the training data\nmodel.fit(\n    series=train_target,\n    future_covariates=future_covariates,\n    val_series=val_target,\n    val_future_covariates=future_covariates,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:01:54.555174Z","iopub.execute_input":"2024-05-21T14:01:54.555578Z","iopub.status.idle":"2024-05-21T14:04:07.161980Z","shell.execute_reply.started":"2024-05-21T14:01:54.555546Z","shell.execute_reply":"2024-05-21T14:04:07.160877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation Step","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(len(val_target))\n\nsegment = 'bildirimsiz_sum_ilce_izmir-cesme'\n\nplt.figure(figsize=(16, 5))\n\ntrain_target[segment][-30:].plot(label=\"train\")\nval_target[segment].plot(label=\"val\")\nprediction[segment].plot(label=\"pred\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:04:07.164368Z","iopub.execute_input":"2024-05-21T14:04:07.165366Z","iopub.status.idle":"2024-05-21T14:04:07.782352Z","shell.execute_reply.started":"2024-05-21T14:04:07.165322Z","shell.execute_reply":"2024-05-21T14:04:07.781179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction Step","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(29, val_target)\n\nsegment = 'bildirimsiz_sum_ilce_izmir-cesme'\n\nplt.figure(figsize=(16, 5))\n\nval_target[segment].plot(label=\"val\")\nprediction[segment].plot(label=\"pred\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T14:04:07.784389Z","iopub.execute_input":"2024-05-21T14:04:07.784941Z","iopub.status.idle":"2024-05-21T14:04:08.432817Z","shell.execute_reply.started":"2024-05-21T14:04:07.784897Z","shell.execute_reply":"2024-05-21T14:04:08.431658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"# Read the sample submission DataFrame and initialize the \"bildirimsiz_sum\" column to 0\ndf_subm = get_subm(root / \"sample_submission.csv\")\ndf_subm[\"bildirimsiz_sum\"] = 0\n\n# Define parameters for experimentation\nseeds = [24, 42]\nlevels = [\"il\"]\nhours = [\"6h\", \"8h\", \"12h\", \"24h\"]\n\n# Iterate through combinations of seed, level, and hour using tqdm for progress tracking\nfor seed, level, hour in tqdm(product(seeds, levels, hours)):\n\n    # Obtain weather data and preprocess it\n    df_weather = get_weather(root / \"weather.csv\", weather_schema, hour, level)\n    \n    # Obtain and preprocess data for training and testing\n    df_data = get_data(root / \"train.csv\", root / \"test.csv\")\n    df_data = feature_eng(df_data, df_weather)\n    \n    # Convert DataFrame to TimeSeries and fill missing values\n    series = to_timeseries(df_data)\n    series = fill_missing_values(series)\n    \n    # Extract target columns and future covariate columns\n    is_target = series.columns.str.contains(\"bildirimsiz_sum\")\n    \n    target_cols = list(series.columns[is_target])\n    future_covariate_cols = list(series.columns[~is_target])\n    \n    future_covariates = series[future_covariate_cols]\n\n    # Split the time series into training and test sets based on a specific date\n    train_series, test_series = series.split_before(pd.Timestamp(\"20240201\"))\n\n    # Extract target variables from the training set\n    train_target = train_series[target_cols]\n    \n    # Define an ensemble model consisting of two TSMixer models\n    model = NaiveEnsembleModel([\n        TSMixerModel(\n            input_chunk_length=12,\n            output_chunk_length=4,\n            n_epochs=100,\n            batch_size=42,\n            add_encoders=encoders,\n            optimizer_kwargs={\"lr\": 0.00044837740437313645},\n            loss_fn=torch.nn.L1Loss(),\n            norm_type=\"LayerNorm\",\n            activation=\"ReLU\",\n            num_blocks=4,\n            ff_size=54,\n            hidden_size=63,\n            random_state=seed,\n            pl_trainer_kwargs={\"accelerator\": \"gpu\"}, # Uncomment for GPU acceleration\n        ),\n        TSMixerModel(\n            input_chunk_length=12,\n            output_chunk_length=4,\n            n_epochs=100,\n            batch_size=45,\n            add_encoders=encoders,\n            optimizer_kwargs={\"lr\": 0.00031599893639713627},\n            loss_fn=torch.nn.L1Loss(),\n            norm_type=\"TimeBatchNorm2d\",\n            activation=\"ReLU\",\n            num_blocks=4,\n            ff_size=82,\n            hidden_size=72,\n            random_state=seed,\n            pl_trainer_kwargs={\"accelerator\": \"gpu\"}, # Uncomment for GPU acceleration\n        )\n    ])\n    \n    # Fit the ensemble model to the training data\n    model.fit(\n        series=train_target,\n        future_covariates=future_covariates,\n    )\n\n    # Generate predictions for the test set\n    prediction = model.predict(29, verbose=False)\n    prediction = handle_pred(prediction)\n    \n    # Update the \"bildirimsiz_sum\" column in the sample submission DataFrame with the predicted values\n    df_subm[\"bildirimsiz_sum\"] += prediction[\"bildirimsiz_sum\"] / 8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_subm[\"bildirimsiz_sum\"] = df_subm[\"bildirimsiz_sum\"].round()\n\ndf_subm.to_csv(\"submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}